# ğŸš€ Building an Intelligent Resume Transformer with LangGraph and GPT-4o-mini

Read the complete medium article here [Building an Intelligent Resume Transformation Agent Powered by LangGraph and gpt-4o-mini](https://medium.com/towards-artificial-intelligence/building-an-intelligent-resume-transformation-agent-powered-by-langgraph-and-gpt-4o-mini-2fbb3004dcd3)

*Transform unstructured resumes into structured, searchable data using AI-powered agents*

---

## The Problem: Resume Chaos in Modern Hiring

Every recruiter knows the pain: hundreds of resumes in different formats (PDF, DOCX, TXT), inconsistent layouts, varying structures, and no easy way to search through them. Modern Applicant Tracking Systems automatically parse resumes, but parsing errors and inconsistencies are common. As a result, HR teams still spend significant time validating and correcting extracted data.

**What if we could automatically transform any resume into a structured, searchable database?**

That's exactly what this Resume Transformer Agent does.

---

## ğŸ¯ What This Project Does

This is an **intelligent resume processing pipeline** built with **LangGraph** and **OpenAI's GPT-4o-mini** that:

1. **Parses** resumes from multiple formats (PDF, DOCX, TXT) â€” even image-based PDFs with OCR
2. **Extracts** structured data using AI (contact info, experience, education, skills)
3. **Validates & Enriches** the data (calculates years of experience, standardizes skills)
4. **Stores** everything in a queryable SQLite database

The result? A fully automated Applicant Tracking System (ATS) that can process resumes at scale.

---

## ğŸ“ Project Structure

```
resume-transformer-agent/
â”‚
â”œâ”€â”€ README.md                          # This file - comprehensive project documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env                              # Environment variables (API keys) - not in repo
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”‚
â”œâ”€â”€ resume-transformer-agent.ipynb    # Main Jupyter notebook with complete workflow
â”‚
â”œâ”€â”€ data/                             # Sample resume files for testing
â”‚   â”œâ”€â”€ *.pdf                        # PDF resume samples
â”‚   â”œâ”€â”€ *.docx                       # DOCX resume samples
â”‚   â””â”€â”€ *.txt                        # Text resume samples
â”‚
â””â”€â”€ resume_ats.db                     # SQLite database (auto-generated)
    â”œâ”€â”€ candidates table              # Main candidate information
    â”œâ”€â”€ experience table              # Work history entries
    â”œâ”€â”€ education table               # Educational background
    â”œâ”€â”€ skills table                  # Normalized skills
    â””â”€â”€ certifications table          # Professional certifications
```

Please note, For simplicity and readability, this article uses the term agent to describe both Python-based workflow functions and the AI-powered extraction component. Only the extraction step uses a true AI agent backed by GPT-4o-mini, while the other agents are deterministic Python functions orchestrated within the workflow.
---

## âœ¨ Key Features

### ğŸ” Multi-Format Resume Parsing
- **PDF Support**: Extract text from regular PDFs
- **OCR Support**: Process image-based PDFs using Tesseract
- **DOCX & TXT**: Handle Microsoft Word documents and plain text files

### ğŸ¤– AI-Powered Data Extraction
- Uses **GPT-4o-mini** to intelligently extract structured data
- Handles various resume formats and layouts
- Normalizes data to consistent schema

### ğŸ› ï¸ Intelligent Data Processing
- **Automatic Experience Calculation**: Computes total years of experience
- **Skill Standardization**: Maps skills to company taxonomy (Python, React, AWS, etc.)
- **Data Validation**: Cleans contact info, validates emails, formats dates

### ğŸ’¾ Structured Database Storage
- **SQLite Database**: Efficient, portable storage
- **Normalized Schema**: Separate tables for candidates, experience, education, skills
- **Query Support**: Search by skills, experience, location, and more

### ğŸ“Š Batch Processing
- Process multiple resumes at once
- Progress tracking and error handling
- Detailed reporting of successes and failures

---

## ğŸ—ï¸ Architecture: The Four-Agent Workflow

This project uses **LangGraph** to orchestrate four specialized agents in a sequential workflow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   START      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PARSE       â”‚  â† Extract raw text from file
â”‚  Agent          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. EXTRACT     â”‚  â† Use GPT-4o-mini to structure data
â”‚  Agent          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. VALIDATE    â”‚  â† Clean, enrich, standardize
â”‚  & ENRICH       â”‚
â”‚  Agent          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. HITL        â”‚  â† Manual review by human
â”‚  HUMAN IN THE.  â”‚
â”‚  LOOP           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. STORE       â”‚  â† Insert into database
â”‚  Agent          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    END       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 1: Parse Agent (Python Based function) ğŸ“„
**Responsibility**: Extract raw text from resume files

- Handles PDF, DOCX, and TXT formats
- Falls back to OCR for image-based PDFs
- Robust error handling

### Step 2: Extract Agent (LLM Powered) ğŸ¤–
**Responsibility**: Transform raw text into structured JSON

- Uses GPT-4o-mini for intelligent extraction
- Follows strict JSON schema
- Extracts: contact info, summary, experience, education, skills, certifications

### Step 3: Validate & Enrich Agent (Python Based function) âœ¨
**Responsibility**: Clean and enhance the data

- Validates email addresses and phone numbers
- Calculates total years of experience
- Standardizes skills to company taxonomy
- Adds metadata (processing date, version)


### Step 4: HITM  (Human in the loop) ğŸ’¾
**Responsibility**: Allowing user to validate the extracted data side by side

- Creates a side by side view on the resume and the extracted fields in HTML file
- User can edit the extracted data

### Step 5: Store Agent  (Python Based function) ğŸ’¾
**Responsibility**: Persist data to database

- Creates SQLite database if it doesn't exist
- Inserts candidate data across normalized tables
- Returns database ID for reference

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- OpenAI API key
- (Optional) Tesseract for OCR support

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/resume-transformer-agent.git
cd resume-transformer-agent
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up your OpenAI API key**
```bash
# Create a .env file
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

4. **(Optional) Install OCR support**
```bash
# macOS
brew install tesseract

# Ubuntu/Debian
sudo apt-get install tesseract-ocr

# Then install Python packages
pip install pytesseract pdf2image pillow
```

### Quick Start

Open the Jupyter notebook and run:

```python
from pathlib import Path

# Process a single resume
result = process_resume("data/sample_resume.pdf")

if result['success']:
    print(f"âœ… Processed: {result['candidate_name']}")
    print(f"ğŸ“Š Database ID: {result['database_id']}")
```

---

## ğŸ“– Usage Examples

### Process a Single Resume

```python
result = process_resume("path/to/resume.pdf")

if result['success']:
    validated_data = result['state']['validated_data']
    print(f"Candidate: {validated_data['contact']['name']}")
    print(f"Experience: {validated_data['total_years_experience']} years")
    print(f"Skills: {', '.join(validated_data['skills'][:5])}")
```


### Query the Database

```python
# Find Python developers
search_by_skill("Python")

# Find candidates with 5+ years experience
search_by_experience(5.0)

# View all candidates
query_database()
```

---

## ğŸ—„ï¸ Database Schema

The system uses a normalized SQLite schema:

### `candidates` table
- Basic info: name, email, phone, location
- Links: LinkedIn, GitHub
- Metadata: total experience, processing date

### `experience` table
- Work history entries
- Company, title, dates, description
- Foreign key to candidates

### `education` table
- Educational background
- Institution, degree, field, graduation year
- Foreign key to candidates

### `skills` table
- Individual skills (normalized)
- Foreign key to candidates

### `certifications` table
- Professional certifications
- Foreign key to candidates

---

## ğŸ¨ Advanced Features

### Skill Standardization

The system automatically maps skills to a standard taxonomy:

```python
'python' â†’ 'Python'
'reactjs' â†’ 'React'
'k8s' â†’ 'Kubernetes'
'ml' â†’ 'Machine Learning'
```

This ensures consistent skill matching across resumes.

### Experience Calculation

Automatically calculates total years of experience from work history:

```python
Job 1: 2020-01 to 2022-06  â†’ 2.5 years
Job 2: 2022-07 to Present   â†’ 2.5 years
Total: 5.0 years
```

### OCR Support

For image-based PDFs (scanned resumes), the system automatically:
1. Detects no text extraction
2. Converts PDF pages to images
3. Applies Tesseract OCR
4. Extracts text from images

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Orchestration** | LangGraph |
| **LLM** | OpenAI GPT-4o-mini |
| **PDF Parsing** | PyPDF2 |
| **DOCX Parsing** | python-docx |
| **OCR** | Tesseract + pdf2image |
| **Database** | SQLite3 |
| **Environment** | Python 3.8+ |

---



## ğŸ“ License

MIT License - feel free to use this project for your own applications!

---

## ğŸ™ Acknowledgments

Built with:
- [LangGraph](https://github.com/langchain-ai/langgraph) for workflow orchestration
- [OpenAI](https://openai.com/) for GPT-4o-mini
- [PyPDF2](https://pypdf2.readthedocs.io/) for PDF parsing
- [Tesseract](https://github.com/tesseract-ocr/tesseract) for OCR

---

## ğŸ“§ Contact

Questions? Issues? Reach out or open an issue on GitHub!

---

**Happy Resume Processing! ğŸ‰**

*Transform chaos into structure, one resume at a time.*
